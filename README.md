همانطور که مشاهده میشود, سرور با fastapi توسط داگر کامپوز همراه یک دیتابیس بالا آورده شده و درخواست های 200 گرفته شده:
![image](https://github.com/user-attachments/assets/15af87b5-768b-4551-9236-6f627ab0d6fb)
![image](https://github.com/user-attachments/assets/ccd4c438-11fb-42b6-ad74-6ad95206d916)





با ران کردن داکر کامپوز تغییر یافته مشاهده می‌شود که سه بکند اجرا شده و دیتابیس اجرا شده و nginx بالا آمده و درخواست‌ها با این که به 23008 رفته و توسط nginx که همان interface سیستم است, بین سرورهای بکند تقسیم می‌شوند.

![image](https://github.com/user-attachments/assets/c8508cf2-3027-49c5-bb41-b8137e4c8f96)


![image](https://github.com/user-attachments/assets/a0f97515-dbe6-4b7a-b081-a4355f8f9f1b)

![image](https://github.com/user-attachments/assets/ad91bffe-b712-40bb-9ec1-22198e00a6cc)

# تست بارگذاری (Load Test) - فایل `test_load.py`

این اسکریپت یک آزمایش بارگذاری همزمان به سرویس FastAPI انجام می‌دهد. در زیر اجزای اصلی آن آورده شده است:

## 1. **تابع اصلی: `run_load_test(num_requests=100, concurrent_requests=10)`**
- ارسال **100 درخواست** کلی
- پردازش **10 درخواست همزمان**
- اندازه‌گیری **زمان کل عملیات**
- جمع‌آوری **آمار پاسخ‌ها** از سرور

## 2. **تابع درخواست واحد: `make_request()`**
- ارسال یک **درخواست GET** به نقطه پایانی `/health`
- ثبت موارد زیر:
  - **کد وضعیت**
  - **محتوای پاسخ** (شامل سروری که پاسخ داده است)
  - **زمان ثبت درخواست**

## 3. **تحلیل نتایج**
نتایج شامل موارد زیر محاسبه می‌شود:
- مدت زمان **کل** تست
- تعداد **درخواست‌ها در هر ثانیه**
- تعداد **موفقیت‌ها و شکست‌ها**
- **توزیع درخواست‌ها** میان سرورها (`api1`, `api2`, `api3`)

## 4. **خروجی**
خلاصه‌ای از نتایج چاپ می‌شود که شامل موارد زیر است:
- مدت زمان **کل تست**
- نرخ **پردازش درخواست‌ها**
- نرخ **موفقیت**
- **توزیع درخواست‌ها** در میان سرورها

این اسکریپت به تأیید عملکرد صحیح **متوازن‌سازی بار** و اطمینان از پردازش درخواست‌ها توسط تمامی نمونه‌های سرور کمک می‌کند.

![IMAGE 2024-12-07 20:50:22](https://github.com/user-attachments/assets/4e125e04-2116-44da-97e9-6c4fcaeef5a0)

---

## سوال‌ها:

<div dir="rtl">

### 1. **<span dir="ltr">Stateless</span> بودن در پیاده‌سازی**
**<span dir="ltr">Stateless</span>** به این معنا است که هر درخواست کاملاً مستقل و خودکفا است و هیچ وابستگی به درخواست‌های قبلی ندارد. در پیاده‌سازی ما:
- هر سرور **<span dir="ltr">بک‌اند</span>** می‌تواند هر درخواستی را پردازش کند زیرا هیچ حالت سشن بر روی سرورها ذخیره نمی‌شود.
- تمامی داده‌های پایدار در پایگاه داده مشترک **<span dir="ltr">PostgreSQL</span>** ذخیره می‌شوند.
- چندین نمونه **<span dir="ltr">API</span>** می‌توانند درخواست‌ها را به‌طور متناوب از طریق **<span dir="ltr">متوازن‌کننده بار</span>** (**<span dir="ltr">load balancer</span>**) سرویس‌دهی کنند.
- هر درخواست تمام اطلاعات مورد نیاز برای پردازش را در خود دارد.

### 2. **بارگذاری متوازن در لایه 4 و 7**
- **بارگذاری متوازن در لایه 4**:
  - در سطح **<span dir="ltr">TCP/UDP</span>** کار می‌کند.
  - سریع‌تر و کم‌هزینه‌تر از نظر منابع.
  - نمی‌تواند محتوای واقعی درخواست‌ها را مشاهده کند.
  - مناسب برای توزیع ترافیک ساده.
  
- **بارگذاری متوازن در لایه 7**:
  - در سطح **<span dir="ltr">HTTP/HTTPS</span>** کار می‌کند.
  - می‌تواند تصمیمات خود را بر اساس محتوای درخواست بگیرد.
  - پرهزینه‌تر از نظر منابع اما هوشمندتر.
  - قادر به مدیریت مسیریابی بر اساس محتوا.

#### چرا از لایه 7 استفاده کردیم؟
در آزمایش ما از **بارگذاری متوازن لایه 7 با <span dir="ltr">Nginx</span>** استفاده کردیم زیرا:
- <span dir="ltr">Nginx</span> با تنظیمات خاص **<span dir="ltr">HTTP</span>** (مثل `proxy_set_header Host $host`) پیکربندی شده است.
- متوازن‌کننده بار ما می‌تواند درخواست‌های **<span dir="ltr">HTTP</span>** را درک و مسیریابی کند.
- می‌توانیم **<span dir="ltr">بررسی سلامت</span>** در سطح برنامه را مشاهده کنیم.
- مسیریابی نقطه پایانی `/health` در سطح **<span dir="ltr">HTTP</span>** انجام می‌شود.

این به ما این امکان را می‌دهد که کنترل بیشتری بر توزیع درخواست‌ها داشته باشیم و نظارت بهتری بر خدمات خود انجام دهیم.

</div>

